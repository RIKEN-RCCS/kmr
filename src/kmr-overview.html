<!-- kmr-overview.html (2014-02-04) -*- Mode: HTML; Coding: utf-8; -*- -->

<p>Copyright (C) 2012-2015 RIKEN AICS</p>

<p>(KMR Version: v1.6(20150401))</p>

<p>
KMR comes with ABSOLUTELY NO WARRANTY.

<P>
Contents (in this page):
<ul>
<li><a href="#overview" >Overview</a>
<li><a href="#targetapplications">Target Applications</a>
<li><a href="#informationandbugreportingetc">Information and Bug Reporting, etc.</a>
<li><a href="#installation">Installation</a>
<li><a href="#applicationcompilation">Application Compilation</a>
<li><a href="#simplestusage">Simplest Usage</a>
<li><a href="#sortingkeyvalues">Sorting Key-Values</a>
<li><a href="#rankawarecommunication">Rank-Aware Communication</a>
<li><a href="#masterslavemapper">Master-Slave Mapper</a>
<li><a href="#fileaccesssupport">File Access Support</a>
<li><a href="#checkpointrestart">Checkpoint/Restart</a>
<li><a href="#kmrrun">Run Arbitrary Programs in MapReduce Model (KMRRUN)</a>
<li><a href="#shellcommandpipeline">Shell Command Pipeline</a>
<li><a href="#auxiliary">Auxiliary Functions</a>
<li><a href="#spawning">Spawning Mappers</a>
<li><a href="#examplecode">Example Code</a>
<li><a href="#appendixkmrbasics">Appendix: KMR Basics</a>
<li><a href="#appendixconfigurechanges">Appendix: Configure Changes</a>
</ul>

<a name="overview"></a>
<h1>Overview</h1>

<p>
KMR (/ke-moo-r/) is a set of high-performance map-reduce operations in
the MPI (Message Passing Interface) environment.  Its targets include
large-scale supercomputers with thousands nodes, especially ones such
as the K computer and Fujitsu FX10.  But, KMR works on ordinary
clusters as well.

<p>
KMR is designed to work on memory exploiting the large amount of
memory available on supercomputers, whereas most other map-reduce
implementations are designed to work with external disk-based
operations.  So, data exchanges in KMR occur as message passing
instead of remote file operations.  In this respect, KMR provides
higher-level wrappers to the message passing routines.  Applications
using KMR work in bulk-synchronous and single-threaded, but its
implementation inside of mappers and reducers is multi-threaded for
performance.

<a name="targetapplications"></a>
<h1>Target Applications</h1>

<p>
KMR's primary goal is to help computational scientists write programs
for post-processing of simulation data.  Post-processing typically
involves large amount of data and needs non-trivial effort of parallel
programming.  It is tedious to write a program of large-scale data
processing with the raw message passing form, but the map-reduce model
will make it less tedious, which is being accepted widely for
programming data-intensive applications during the past decade.

<p>
KMR makes communications implicit, which frees programmers from the
details of MPI ranks, tags, message lengths, race conditions, etc.
KMR also eases programming with platform specifics, which sometimes
make simple tasks more complicated.  For example, the access practice
on the file-system on K has affinity on the z-axis of the Tofu
network, intended to lessen the disturbance to the communication of
the other users.  With this practice, a segment of a file were thought
to exist in some virtual partition, and it is necessary keep an
association from a segment of a file to a specific rank/node.  KMR
includes routines for this association.

<a name="informationandbugreportingetc"></a>
<h1>Information and Bug Reporting, etc.</h1>

<p>
See <a href="http://mt.aics.riken.jp/kmr">"http://mt.aics.riken.jp/kmr"</a>
for up-to-date information and issue tracking.

<a name="installation"></a>
<h1>Installation</h1>

<p>
Do configure, make, and make install.  Make install copies
commands/scripts, "kmr.h", "libkmr.a", and document files in "html" to
the destination (specified by --prefix).  Destinations are "bin",
"include", "lib", "etc", "man", and "doc/html" in the "prefix"
directory.  Only a few configure options affect KMR behavior (the
first line shows the default):

<pre class="fragment">
./configure --prefix=/usr/local --disable-debug --enable-assert --enable-openmp --enable-fortran
    [--enable-debug/--disable-debug]
    [--enable-assert/--disable-assert]
    [--enable-openmp/--disable-openmp]
    [--enable-fortran/--disable-fortran]
</pre>

<p>
Normally, the following suffices:

<pre class="fragment">
./configure --prefix=$HOME/lib/kmr
</pre>

<p>
See "config.make" for the configuring result.

<p>
KMR also works on ordinary cluster computers.  To configure properly,
the MPI (Message Passing Interface) is needed.  Prepare the MPI
library first.  The configurer uses the modified versions of
"ax_mpi.m4" and "ax_openmp.m4", to find the compiler driver scripts
for MPI and the compiler flags for OpenMP.  They are modified to be
able to find compiler flags for Fujitsu compliers on the K computer
(which are with unusual names).

<a name="applicationcompilation"></a>
<h1>Application Compilation</h1>

<p>
Applications can be compiled as usual.  Compiler/linker options
necessary (or recommended) to Fujitsu compilers on the K computer are:
<pre class="fragment">
mpifccpx -g -Kfast -Kopenmp
</pre>

<p>
Compiled applications can be run as usual, too, via "mpirun" or
"mpiexec".

<p>
Setting an environment variable "XOS_MMM_L_ARENA_FREE=2" at run time
may help improve performance on the K computer, because KMR frequently
calls malloc/free.  It prohibits returning memory pages to the kernel
pool at free (the effect was not evaluated).

<a name="simplestusage"></a>
<h1>Simplest Usage</h1>

<p>
Specific features of the KMR API are, first of all, that it has types
in keys and values; i.e., integer, floating-point, and byte data
(opaque).  Second, KMR has a separate call to shuffling, and shuffling
must be explicitly called in advance to reduction.  Since a reducer
itself reduces data local to rank/node, a local "combiner" can be
implemented by running a reducer without shuffling.  Third, each steps
of mapping, shuffling, and reducing are separate calls with specific
API, and run in step-by-step "bulk-synchronously".  It is arguable
that synchronous behavior looks not the best for the performance, but
it allows to utilize efficient collective communication of MPI, which
become more important on very large-scale computers.  Fourth, sorting
after reduction is also optional, and KMR provides a separate call to
sorting.

<p>
The following is the simplest usage.  It is "wordcount.c" in the
example directory.  See the section <a href="#examplecode">Example
Code</a>.

<p>View the source code listing:
<a href="wordcount_8c_source.html">wordcount.c</a>.

<pre class="fragment">
/* Word Count */

/* It ranks the words by their occurrence count in the "LICENSE" file.
   Copy the file in the current directory and run it. */

#include &lt;mpi.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;unistd.h&gt;
#include "kmr.h"

#define ISALPHA(X) (('a' &lt;= X &amp;&amp; X &lt;= 'z') || ('A' &lt;= X &amp;&amp; X &lt;= 'Z'))

static int
read_words_from_a_file(const struct kmr_kv_box kv0,
     const KMR_KVS *kvi, KMR_KVS *kvo, void *p, const long i)
{
    char b[25];
    assert(kvi == 0 &amp;&amp; kv0.klen == 0 &amp;&amp; kv0.vlen == 0 &amp;&amp; kvo != 0);
    FILE *f = fopen("LICENSE", "r");
    if (f == 0) {
	perror("Cannot open a file \"LICENSE\"; fopen(LICENSE)");
	MPI_Abort(MPI_COMM_WORLD, 1);
	return 0;
    }
    int j = 0;
    for (;;) {
	assert((size_t)j &lt;= (sizeof(b) - 1));
	int cc = getc(f);
	if ((cc == EOF || !ISALPHA(cc) || (j == (sizeof(b) - 1))) &amp;&amp; j != 0) {
	    b[j] = 0;
	    struct kmr_kv_box kv = {
		.klen = (j + 1), .k.p = b,
		.vlen = sizeof(long), .v.i = 1};
	    kmr_add_kv(kvo, kv);
	    j = 0;
	}
	if (cc == EOF) {
	    break;
	}
	if (ISALPHA(cc)) {
	    b[j] = cc;
	    j++;
	}
    }
    fclose(f);
    return MPI_SUCCESS;
}

static int
print_top_five(const struct kmr_kv_box kv0,
      const KMR_KVS *kvi, KMR_KVS *kvo, void *p, const long i)
{
    int rank = kvi-&gt;c.mr-&gt;rank;
    if (rank == 0 &amp;&amp; i &lt; 5) {
	printf("#%s=%d\n", kv0.v.p, (int)(0 - kv0.k.i));
	fflush(0);
    }
    return MPI_SUCCESS;
}

static int
sum_counts_for_a_word(const struct kmr_kv_box kv[], const long n,
    const KMR_KVS *kvs, KMR_KVS *kvo, void *p)
{
    long c = 0;
    for (long i = 0; i &lt; n; i++) {
	c -= kv[i].v.i;
    }
    struct kmr_kv_box nkv = {
	.klen = kv[0].klen,
	.k.p = kv[0].k.p,
	.vlen = sizeof(long),
	.v.i = c};
    kmr_add_kv(kvo, nkv);
    return MPI_SUCCESS;
}

int
main(int argc, char **argv)
{
    int nprocs, rank, thlv;
    MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_SERIALIZED, &amp;thlv);
    MPI_Comm_size(MPI_COMM_WORLD, &amp;nprocs);
    MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
    kmr_init();
    KMR *mr = kmr_create_context(MPI_COMM_WORLD, MPI_INFO_NULL, 0);

    MPI_Barrier(MPI_COMM_WORLD);
    if (rank == 0) {printf("Ranking words...\n");}

    /* Insert words with count 1 to a KVS: */
    KMR_KVS *kvs0 = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_INTEGER);
    kmr_map_once(kvs0, 0, kmr_noopt, 0, read_words_from_a_file);

    /* Gather the same words for summing their counts: */
    KMR_KVS *kvs1 = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_INTEGER);
    kmr_shuffle(kvs0, kvs1, kmr_noopt);

    /* Sum counts for words: */
    KMR_KVS *kvs2 = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_INTEGER);
    kmr_reduce(kvs1, kvs2, 0, kmr_noopt, sum_counts_for_a_word);

    /* Swap words and counts, and make counts as keys: */
    KMR_KVS *kvs3 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
    kmr_reverse(kvs2, kvs3, kmr_noopt);

    /* Rank by count: */
    KMR_KVS *kvs4 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
    kmr_sort(kvs3, kvs4, kmr_noopt);

    /* Print the first few entries: */
    kmr_map(kvs4, 0, 0, kmr_noopt, print_top_five);

    kmr_free_context(mr);
    kmr_fin();
    MPI_Finalize();
    return 0;
}
</pre>

<p>
The following list shows often used functions with short descriptions.

<dl class="note">
<dt>MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_SERIALIZED, &amp;thlv)
<dd>initializes MPI.  MPI must be initialized with threads enabled,
because KMR uses threads.

<dt><a href="kmr_8h.html#a89dc005f93cbfdcdb0eebc302350a912">kmr_init()</a>
<dd>initializes the KMR environment.

<dt><a href="kmrbase_8c.html#a562467c4832bfdb13027976e7eb9c5bf">kmr_create_context(MPI_COMM_WORLD, MPI_INFO_NULL, 0)</a>
<dd>initializes a KMR context with a given communicator.  The context
records common information needed by all key-values.

<dt><a href="kmrbase_8c.html#ade6559203d1471e48688314ba729758a">kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_OPAQUE)</a>
<dd>makes a new key-value stream used mappers and reducers.

<dt><a href="kmrbase_8c.html#a151c51b13af3b5dffe5124cc64335ceb">kmr_map(kvs0, kvs1, 0, kmr_noopt, mapfn)</a>
<dd>maps data by calling "mapfn" on "kvs0" as an input and "kvs1" as
an output.

<dt><a href="kmr_8h.html#aa4a5c672a7f963f4c6f9106accd2c008">int
mapfn(const struct kmr_kv_box kv, const KMR_KVS *kvi,
	KMR_KVS *kvo, void *p, const long index)</a>
<dd>is a map-function.

<dt><a href="kmrbase_8c.html#ab58641ce4b8c06e61f3e21606b7fed36">kmr_map_on_rank_zero(kvs0, 0, kmr_noopt, mapfn)</a>
<dd>is a variant of mappers, which runs a map-function on rank zero only.

<dt><a href="kmrbase_8c.html#a815a3eafd8bde396d34bbf5f39ba9783">kmr_map_once(kvs0, 0, kmr_noopt, 0, mapfn)</a>
<dd>is a variant of mappers, which runs a map-function once with a dummy input.

<dt><a href="kmrbase_8c.html#a194686701b3c46a869fe9eb2cab93252">kmr_shuffle(kvs1, kvs2, kmr_noopt)</a>
<dd>shuffles data from kvs1 to kvs2.

<dt><a href="kmrbase_8c.html#a54e4b9b350dccc8dd4d0f96c8bf9aeeb">kmr_reduce(kvs2, kvs3, 0, kmr_noopt, reducefn)</a>
<dd>reduces data by calling "reducefn" on "kvs2" as an input and
"kvs3" as an output.

<dt><a href="kmr_8h.html#ad807855471657a0ae5cfe724a657e20a">int
reducefn(const struct kmr_kv_box kv[], const long n,
	const KMR_KVS *kvi, KMR_KVS *kvo, void *p)</a>
<dd>is a reduce-function.

<dt><a href="kmrbase_8c.html#a642656490e91b16d31f4253e35d8e03c">kmr_free_kvs(kvs3)</a>
<dd>frees a key-value stream.  Normally, key-value streams are
consumed by mappers and reducers and explicit calls of it are not
necessary.

<dt><a href="kmrmoreops_8c.html#a43dc49274f766b46b16ec77b0217c6ca">kmr_sort(kvs3, kvs4, kmr_noopt)</a>
<dd>sorts key-values.

<dt><a href="kmrmoreops_8c.html#aa50e7437f8d24e7c50927f21b0ad9d44">kmr_reverse(kvs2, kvs3, kmr_noopt)</a>
<dd>swaps the key part and the value part in each pair.

<dt><a href="kmrutil_8c.html#a835fbe3cbeddee74050f96e1fb1145a9">kmr_dump_kvs(kvs1, 0)</a>
<dd>dumps key-value pairs in "kvs1".

<dt><a href="kmrbase_8c.html#ad7d12efd914c8b60a54eb82b7a930ea7">kmr_free_context(mr)</a>
<dd>releases the common context.

<dt><a href="kmrbase_8c.html#a617746ae8bd9b8bd6f8af9b4ca6e1733">kmr_fin()</a>
<dd>terminates the use of KMR.

<dt>MPI_Finalize()
<dd>is needed as usual.
</dl>

<p>
See <a href="kmr_8h.html#details">descriptions in kmr.h</a>.

<p>
For the next step, browse documents starting with
<a href="test0_8c_source.html#l00119">simple0 in test0.c</a>.

<a name="sortingkeyvalues"></a>
<h1>Sorting Key-Values</h1>

<p>
KMR does not sort key-value pairs after reduction.  There is a
separate call for sorting,
<a href="kmr_8h.html#a43dc49274f766b46b16ec77b0217c6ca">kmr_sort()</a>.

<p>
The sorter sorts the keys by the content types, that is, signed
integers, floating-point numbers, or byte arrays.  Byte arrays are
sorted by the lexicographical ordering on bytes.  Floating-point
numbers are sorted as integers after some conversions to handle
negative values.

<a name="rankawarecommunication"></a>
<h1>Rank-Aware Communication</h1>

<p>
It is normally not necessary to use ranks explicitly in the model of
map-reduce.  However, the rank information is sometimes unavoidable,
especially in initializations and operations related to file I/O.  KMR
supports communications with explicit rank information by regarding
the keys as ranks.

<p>
Specifying the option ".key_as_rank" to kmr_shuffle makes the key
field work as a rank, which allows to mimic rank-based communications
of MPI.

<pre class="fragment">
/* Rank-based Communications */
KMR_KVS *kvs0 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
KMR_KVS *kvs1 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
struct kmr_option opt = kmr_noopt;
opt.key_as_rank = 1;
kmr_shuffle(kvs0, kvs1, opt);
</pre>

<p>
See <a href="kmr_8h.html#a194686701b3c46a869fe9eb2cab93252">descriptions in kmr.h</a>.

<p>
Another communication pattern of MPI "allgather" is performed with
kmr_replicate.  It is also often used to "bcast" data from the node
rank=0 to all ranks.  Specifying the option ".rank_zero" to
kmr_replicate makes data "gather" to the node rank=0.

<pre class="fragment">
/* Allgather/Bcast */
KMR_KVS *kvs0 = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_OPAQUE);
KMR_KVS *kvs1 = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_OPAQUE);
kmr_replicate(kvs0, kvs1, kmr_noopt);

/* Gather */
KMR_KVS *kvs0 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
KMR_KVS *kvs1 = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
struct kmr_option opt = kmr_noopt;
opt.rank_zero = 1;
kmr_replicate(kvs0, kvs1, opt);
</pre>

<p>
See <a href="kmr_8h.html#a64d9a689d79d64bcfa10d61c1d335ee7">descriptions in kmr.h</a>.

<p>
There are a few mapping calls to handle key-value pairs.  For using
keys as ranks, it is sometimes wanted to save key information in the
value field.  kmr_pairing() makes each value field be replaced with
key-value pair, keeping the same key field.  kmr_unpairing() recovers
key-value pairs, discarding old key field.  kmr_reverse() swaps the
key and the value fields.

<a name="masterslavemapper"></a>
<h1>Master-Slave Mapper</h1>

<p>
KMR supports a mapper with master-slave job scheduling.  The special
mapper kmr_map_ms distributes key-value pairs on the master (rank0) to
slaves (ranks other than rank0), and collects the resulting key-value
pairs again on the master.  Key-value data is only stored on the
master in this case.

<pre class="fragment">
KMR_KVS *tasks = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
/* Put tasks as key-values here... */
KMR_KVS *results = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
do {
    struct kmr_option opt = kmr_noopt;
    opt.nothreading = 1;
    cc = kmr_map_ms(tasks, results, m, 0, opt);
} while (cc == MPI_ERR_ROOT);
</pre>

<p>
See <a href="kmr_8h.html#a9d52c3c69250bf19dd28d5e38809df79">descriptions in kmr.h</a>.

<p>
There is another master-slave job scheduling, which spawns and runs
new MPI processes.

<pre class="fragment">
KMR_KVS *tasks = kmr_create_kvs(mr, KMR_KV_INTEGER, KMR_KV_OPAQUE);
/* Put tasks as key-values here... */
KMR_KVS *results = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_OPAQUE);
struct kmr_option opt = kmr_noopt;
kmr_map_via_spawn(tasks, resuts, 0, info, opt, 0);
</pre>

<p>
See <a href="kmr_8h.html#a2502be0968e7f62404e02f8f445c7498">descriptions in kmr.h</a>.

<a name="fileaccesssupport"></a>
<h1>File Access Support</h1>

<p>
KMR is intended to ease programming with platform specifics.  As
decribed in the overview section, the access practice on the
file-system on K has affinity on the z-axis of the Tofu network.  It
is actually not for pure performance, but it is the demands by the
administration to lessen the disturbance to the other users.  Besides
affinity, the job-scheuduler uses file-staging which copies data files
and program files to the storage of working area.  File-staging is
designed to respect the affinity on the z-axis.  Users are often
confronted by a problem to read a large data file onto many ranks,
because it is simply a bottleneck.

<p>
One way to read large data is that the user first splits the large
data file into segments, does stage-in, then reassembles them to the
original.  It is easy to distribute the load of file accessing to
multiple z-axes by the description of file-staging.  KMR provides an
routine to support reassembling of the segmented files:

<pre class="fragment">
KMR *mr = ...;
int color = 0;
void *buffer;
off_t size;
kmr_read_files_reassemble(mr, "filepart", color, 0, -1, &buffer, &size);
</pre>

<p>
See <a href="kmr_8h.html#a78f87c0c3724460402376ef81d0efa76">descriptions in kmr.h</a>.

<p>
Another way to read large data is that the user does stage-in the
large data file as a single file as it is, then reads the segments of
the single file from multiple ranks.  This makes a large file on the
file system whose affinity spans to multiple z-axes.  So, it is
necessary to take into account the striping information of the Lustre
file-system to keep file accesses confined to one z-axis.  Each rank
only accesses the parts of a stripe, which are known to be on the same
z-axis.  KMR provides an routine to support segmented access to the
large files:

<pre class="fragment">
KMR *mr = ...;
int color = 0;
void *buffer;
off_t size;
kmr_read_file_by_segments(mr, "largefile", color, &buffer, &size);
</pre>

<p>
See <a href="kmr_8h.html#aa595f06609d414e074f50f3009a90c8f">descriptions in kmr.h</a>.

<p>
There is some utility mappers to ease to enumerate files and
directories.  One such mapper maps on file names, which are specified
or exists in the specified directories.

<pre class="fragment">
KMR *mr = ...;
KMR_KVS *results = kmr_create_kvs(mr, KMR_KV_OPAQUE, KMR_KV_OPAQUE);
char *names[] = {"f0", "f1", "f2"};
int n = 3;
kmr_map_file_names(mr, names, n, kmr_fnoopt, results, 0, kmr_noopt, m);
</pre>

<p>
See <a href="kmr_8h.html#a0cc987ce7e41bef6c36346c5fb0eaf4b">descriptions in kmr.h</a>.

<a name="checkpointrestart"></a>
<h1>Checkpoint/Restart</h1>

<p>
KMR provides a simple checkpoint/restart mechanism to achieve highly
reliable MapReduce execution.  As the checkpoint/restart is implemented
in KMR library, any programs that use kmr functions and MapReduce
programs invoked by <a href="#kmrrun">kmrrun</a> can use the feature.

<h2>Using Checkpoint/Restart in kmrrun</h2>

<p>
To enable checkpoint/restart in kmrrun, users only have to pass "--ckpt"
option to the command.  When "--ckpt" option is given, state of MapReduce
progress is saved as checkpoint files at every MapReduce operation,
such as map, shuffle and reduce.  When "--ckpt" option is given and
if previous checkpoint files exist, the MapReduce execution is restarted
from the saved state.

<h2>Using Checkpoint/Restart in a KMR program</h2>

<p>
To enable checkpoint/restart in a user program that use KMR, users need
to specify an environment variable named KMROPTION.  KMROPTION points to
a kmr resource file that defines behavior of kmr.  Specifying
"ckpt_enable=1" in that file enables checkpoint/restart.

<pre class="fragment">
echo "ckpt_enable=1" > kmrrc
KMROPTION=kmrrc mpiexec -np 12 ./a.out
</pre>

<h3>Checkpointing without fsync</h3>

<p>
If users can assume that the MTBF of the system is much larger than the
expected program execution time, they can disable 'fsync' on writing
checkpoint files by specifying 'ckpt_no_fsync=1' option as follows.
It surely reduces the reliability but also reduces IO overhead, and
as a result, increases performance.

<pre class="fragment">
echo "ckpt_enable=1" > kmrrc
echo "ckpt_no_fsync=1" >> kmrrc
KMROPTION=kmrrc mpiexec -np 12 ./a.out
</pre>

<p>
It may be helpful when users run a job in a short maximum elapsed time
queue, such as 'micro' queue in the K computer.
Though the job would be killed by the job scheduler when the elapsed time
is exceeded, checkpoint files are guaranteed to be saved and they can
restart the same program as a new job from the saved states in the
checkpoint files.

<h3>Selective Checkpointing</h3>

<p>
From version 1.6, KMR experimentally supports 'selective mode' in
saving checkpoint files to further reduce IO overhead.
By enabling selective mode, KMR saves checkpoint files of only
user-specified key-value streams.

<p>
To enable selective mode, specify the following environment variables.

<pre class="fragment">
echo "ckpt_enable=1" > kmrrc
echo "ckpt_selective=1" >> kmrrc
KMROPTION=kmrrc mpiexec -np 12 ./a.out
</pre>

<p>
Just enabling this option do not take checkpoints.
To save a checkpoint file of an output key-value stream of a kmr function,
users need to pass 'take_ckpt' option to the function.
In the following example, a checkpoint file of key-value stream named 'kvs1'
is saved.

<pre class="fragment">
struct kmr_option kmr_ckpt = { .take_ckpt = 1 };
kmr_map(kvs0, kvs1, 0, kmr_ckpt, mapfn);
</pre>

This feature is currently highly experimental, be careful to use.

<h3>Supported functions</h3>

<p>
As checkpoint/restart is only supported in the following kmr functions,
programs that use other kmr functions and that stores data outside of
KMR context (key-value stream) can not benefit from the feature.

<dl>
<dt>Map functions
<dd>kmr_map, kmr_map_once, kmr_map_on_rank_zero, kmr_map_rank_by_rank,
  kmr_map_via_spawn, kmr_map_processes, kmr_map_parallel_processes,
  kmr_map_serial_processes, kmr_map_getline, kmr_map_getline_in_memory_,
  kmr_map_for_some

<dt>Reduce functions
<dd>kmr_reduce, kmr_reduce_as_one, kmr_reduce_for_some

<dt>Communication functions
<dd>kmr_shuffle, kmr_replicate

<dt>Other functions
<dd>kmr_move_kvs, kmr_reverse, kmr_pairing, kmr_unpairing,
  kmr_assign_file
</dl>

<p>
We plan to support checkpoint/restart in other kmr functions in the near
future releases.

<a name="kmrrun"></a>
<h1>Run Arbitrary Programs in MapReduce Model (KMRRUN)</h1>

<p>
KMR provides a simple command line tool, named kmrrun, that can run
arbitrary programs as mapper and reducer.  By using kmrrun, users can
easily execute a MapReduce task and also embarrassingly parallel tasks.
kmrrun requires OpenMPI or Fujitsu MPI (for K and FX10).
It does not work with MPICH2 or Intel MPI.

<p>
To run a MapReduce task, users have to prepare the following three programs.

<dl>
<dt>Mapper
<dd>
is a Mapper program.
It should accept a file name as the last command line parameter.
It can be a serial, OpenMP or MPI program.

<dt>Key-Value pair generator
<dd>
is a program that generates key-value pairs by reading output files of
Mapper.  It should accept a file name whose name is the input file to
the Mapper as the last command line parameter.  The generated key-value
pairs should be written to the standard output and key and value should
be separated by a space.  It should be a serial program.

<dt>Reducer
<dd>
is a Reducer program.  It should accept a file name as the last command
line parameter.  The name of the file is key of a key-value pair and
its contents are text where each line is a key-value pair saparated by
a space.  It can be a serial, OpenMP or MPI program.
</dl>

<p>
The command line looks like the following.

<pre class="fragment">
mpiexec -np 12 kmrrun -n 8 -m "mapper arg0 arg1" -k "kvgen.sh" -r "reducer arg0 arg1" file
</pre>

<p>
For command line arguments, see the man-page of
<a href="kmrrun_81.html">kmrrun.1</a>.  Also
see <a href="kmrrun_8c.html">descriptions of kmrrun</a>.

<p>
If the file argument is a regular file, it processes it. Or, if the
argument is a directory, it enumerates regular files under the directory
and processes all the contents of the files. When a mapper or a reducer
has arguments, they are passed as a quoted string separated by a whitespace.

<p>
There are some differences between
<a href="#shellcommandpipeline">kmrshell</a> and kmrrun.

<ul>
<li>Input to a mapper and a reducer of kmrrun are file names as the
  last command line parameter.  On the other hand, input to those of
  kmrshell are passed to the standard input of them. </li>
<li>Output of a mapper and a reducer of kmrrun are files. On the other
  hand, output of those of kmrshell are written to the standard output
  or files</li>
<li>kmrrun can execute serial, OpenMP and MPI programs as mapper and
  reducer.  kmrshell can execute only serial and OpenMP programs.</li>
<li>kmrrun reads inputs from a shared directory. On the other hand,
  kmrshell reads inputs from a node (rank) local directory.</li>
<li>kmrrun supports checkpoint/restart.</li>
</ul>

<p>
KMR provides a tool to use kmrrun on the job-schduler of K: "kmrrungenscript".
"kmrgenscript" generates a job-script for the job-scheduler to use kmrrun.
See the related man-pages.

<ul>
<li><a href="kmrrun_81.html">kmrrun.1</a>, and</li>
<li><a href="kmrrungenscript_81.html">kmrrungenscript.1</a>.</li>
</ul>

<p>
There are a frew examples (pi calculation) for kmrrun that are implemented in
serial C program and MPI/C program.

<ul>
<li><a href="pi_8mapper_8c_source.html">pi.mapper.c</a></li>
<li><a href="pi_8kvgen_8sh_source.html">pi.kvgen.sh</a></li>
<li><a href="pi_8reducer_8c_source.html">pi.reducer.c</a></li>
<li><a href="mpi__pi_8mapper_8c_source.html">mpi_pi.mapper.c</a></li>
<li><a href="mpi__pi_8kvgen_8sh_source.html">mpi_pi.kvgen.sh</a></li>
<li><a href="mpi__pi_8reducer_8c_source.html">mpi_pi.reducer.c</a></li>
</ul>

<a name="shellcommandpipeline"></a>
<h1>Shell Command Pipeline (Streaming)</h1>

<p>
It is often convenient to run shell commands as mappers and reducers.
The function is called "streaming" in Hadoop.  KMR includes a tool
called "kmrshell", which invokes processes of a mapper, a shuffler,
and a reducer, and connects them via Unix pipes.  After invoking
processes, "kmrshell" becomes a file-reader, which concatenates
contents of the input files (if a directory is specified as an input)
and passes the contents to a mapper.

<blockquote>
<pre>
                     pipe        pipe               pipe
input ==> "kmrshell" ---> mapper ---> "kmrshuffler" ---> reducer ==> results
files                 (shell command)                (shell command)
</pre>
</blockquote>

<p>
In a shell command pipeline, key-value data is a line of string "key
value\n", where the fields are separated by a whitespace.  A mapper
should output lines of key-value pair strings, and a reducer should
accept input lines of key-value pair strings.  A reducer will see
consecutive lines having the same key, which are to be reduced.  A
shuffler command is named "kmrshuffler", which is installed in the
"lib" directory.

<p>
The command line looks like the following.

<pre class="fragment">
kmrshell -m "mapper arg0 arg1" -r "reducer arg0 arg1" file
</pre>

<p>
For command line arguments, see the man-page of
<a href="kmrshell_81.html">kmrshell.1</a>.  Also
see <a href="kmrshell_8c.html">descriptions of kmrshell</a>.

<p>
If the file argument is a regular file, it processes it.  Or, if the
argument is a directory, it enumerates regular files under the
directory and processes all the contents of the files.  When a mapper
or a reducer has arguments, they are passed as a quoted string
separated by a whitespace.

<p>
To ease further for using the job-scheduler of K, KMR includes a few
more tools: "kmrfsplit.1", "kmrgenscript.1", and "kmrwrapper.1".
"kmrfsplit" splits a file into almost equally-sized parts, by looking
for a record separator.  "kmrgenscript" generates a job-script for the
job-scheduler to use a shell command pipeline.  "kmrwrapper" combines
above two, to generate a job-script which will handle large files.
"kmrshuffler" is a shuffler program of key-values for "kmrshell".  See
the man-pages of them:
<ul>
<li><a href="kmrshell_81.html">kmrshell.1</a>,</li>
<li><a href="kmrshell_mpi_81.html">kmrshell_mpi.1</a>,</li>
<li><a href="kmrshuffler_81.html">kmrshuffler.1</a>,</li>
<li><a href="kmrfsplit_81.html">kmrfsplit.1</a>,</li>
<li><a href="kmrgenscript_81.html">kmrgenscript.1</a>, and</li>
<li><a href="kmrwrapper_81.html">kmrwrapper.1</a>.</li>
</ul>

<p>
<p>
There are a few examples (word count) of a mapper and a reducer
written in C and Python in the "shell" directory.
<ul>
<li><a href="wc_8mapper_8c_source.html">wc.mapper.c</a></li>
<li><a href="wc_8reducer_8c_source.html">wc.reducer.c</a></li>
<li><a href="wc_8map_8pl_source.html">wc.map.pl</a></li>
<li><a href="wc_8reduce_8pl_source.html">wc.reduce.pl</a></li>
</ul>

<a name="auxiliary"></a>
<h1>Auxiliary Functions</h1>

<p>
KMR provides some variants of mappers and several small functions for
handling KVS.

<dl class="note">

<dt><a href="kmr_8h.html#ab58641ce4b8c06e61f3e21606b7fed36">kmr_map_on_rank_zero(kvo, arg, opt, fn)</a>
<dd>is a variant of mappers, which runs a map-function on rank zero only.

<dt><a href="kmr_8h.html#a815a3eafd8bde396d34bbf5f39ba9783">kmr_map_once(kvo, arg, opt, rank_zero_only, fn)</a>
<dd>is a variant of mappers, which runs a map-function once with a dummy input.

<dt><a href="kmr_8h.html#a40c607730747510fab9abcd2f8ed10fe">kmr_move_kvs(kvi, kvo, opt)</a>
<dd>moves the contents of the input to the output.

<dt><a href="kmr_8h.html#a273d7bee0df5928f5700b3c6bbb31939">kmr_concatenate_kvs(kvs[] nkvs, kvo, opt)</a>
<dd>concatenates the contents of the given KVSes to the output.

<dt><a href="kmr_8h.html#a058890c9ef6689deacfd9eda9d25e513">kmr_distribute(kvi, kvo, cyclic, opt)</a>
<dd>redistributes key-value pairs approximately evenly among ranks for
leveling the load of map processing.

<dt><a href="kmr_8h.html#a7d8d470979d2edbc1d1af235f150e89e">kmr_ranking(kvi, kvo, count, opt)</a>
<dd>assigns a ranking to key-value pairs.  The key part is the ranks.
The value part is an old key-value pair, which can be unpaired by
kmr_unpairing().

<dt><a href="kmr_8h.html#af00f09bbba752958cd1036ceb0aa5aad">kmr_choose_first_part(kvi, kvo, n, opt)</a>
<dd>chooses the first N entries using kmr_ranking().

<dt><a href="kmr_8h.html#aa50e7437f8d24e7c50927f21b0ad9d44">kmr_reverse(kvi, kvo, opt)</a>
<dd>swaps the key part and the value part in each pair.

<dt><a href="kmr_8h.html#aea1ec5745abce4c3b711146b0d4f5ce6">kmr_pairing(kvs, kvo, opt)</a>
<dd>makes a new pair with a key-value pairing in the value part.

<dt><a href="kmr_8h.html#a523095ec2296b560d815d7e082dcb4b1">kmr_unpairing(kvs,
kvo, opt)</a>
<dd>performs an inverse of kmr_pairing(), discarding the old key part.

<dt><a href="kmr_8h.html#af18d7541ca4f6e28c922edb006a388f4">kmr_match(kvi0, kvi1, kvo, opt)</a>
<dd>produces product pairs from the two inputs.  The key-value pairs
are matched by the same key, and pairs are produced by taking the key
from the first KVS and the value from the second KVS.

<dt><a href="kmr_8h.html#a40e2c060cb87fa46364cae1e3038d47f">kmr_histogram_count_by_ranks(kvs, frq, var, rankzeroonly)</a>
<dd>Fills the array with the count of the elements of each rank.

</dl>

<a name="spawning"></a>
<h1>Spawning Mappers</h1>

<p>KMR provides mappers which will start MPI processes via
MPI_Comm_spawn() for map processing, because, it is sometimes
necessary to run application programs to process data.  There are two
map functions.  See
<a href="kmr_8h.html#a2502be0968e7f62404e02f8f445c7498">kmr_map_via_spawn()</a>
and
<a href="kmr_8h.html#a309f2ef87bc5f4ec67d53a446cbb392e">kmr_map_parallel_processes</a>

<p>
DO NOT USE THEM; Consider using the
command <a href="#kmrrun">kmrrun</a>.  The use of spawning mappers is
fairly complicated, because they start separate MPI applications.  It
does not make sense to call map functions as usual, because what is
invoked is a process but not a function, and a key-value need to be
passed as an argument in the command list.  Spawning mappers are
intended to ease the use of MPI_Comm_Spawn(), but it is still
complicated.

<p>
They will be used when you want to run MPI processes as mappers.
However, it is normally difficult, because the job schedulers used in
computer centers prohibit to start MPI processes from MPI processes.
Sometimes, the use of MPI_Comm_spawn() is the only way, and
kmr_map_via_spawn() and kmr_map_parallel_processes() give an easier
way to use MPI_Comm_spawn() from KMR applications.

<p>
The value part of key-values are used as a command line of spawned
processes.  The value part should be a list of null-terminated
strings, which are used as "argv" command strings.  The key part is
ignored.  The number of processes to spawned is specified by the
command line prefix which is the form of string "maxprocs=n".  Or, it
is specified by the MPI_Info entry "maxprocs", when the number of
processes is the same for all spawn invocations.  It invokes
MPI_Comm_spawn() for each key-value.
The value part should look like:
<pre class="fragment">
maxprocs=4\0./a.out\0arg1\0arg2
</pre>

<p>
The difference between kmr_map_via_spawn() and
kmr_map_parallel_processes() is how they wait.  kmr_map_via_spawn()
waits for the spawned processes to return a reply.  It is used when
the MPI application can be modified. The reply is sent by
kmr_reply_to_spawner(). The lack of its call fails to finish the call.
On the other hand, kmr_map_parallel_processes() waits for the exit of
the spawned processes.  It is used when the MPI application cannot be
modified.

<p>
Both kmr_map_via_spawn() and kmr_map_parallel_processes() accept a
map-function.  It is called after the spawned processes are finished.

<p>
KMR provides the pair of functions kmr_receive_kvs_from_spawned_fn()
and kmr_send_kvs_to_spawner() to gather KVS generated by spawned
processes.  kmr_receive_kvs_from_spawned_fn() is a map-function and it
can be passed to kmr_map_via_spawn() as an argument.
kmr_send_kvs_to_spawner() is a utility function which can be called in
the spawned processes. It sends KVS from spawned processes to the
spawner.

<a name="examplecode"></a>
<h1>Example Code</h1>

<p>
There are a few examples in the "ex" directory in addition to the
simplest tests in the "src" directory.  Some are rewrites of
test/example codes of "Phoenix-MapReduce" and "MapReduce-MPI".

<dl>
<dt>
<a href="wordcount_8c_source.html">wordcount.c</a>:
<dd>
is a word count.

<dt>
<a href="test0_8c_source.html">test0.c</a>:
<dd>
is a simplest test code.  It is not an example, but a test.

<dt>
<a href="testf_8f90_source.html">testf.f90</a>:
<dd>
is a simplest test code in Fortran (F2003).

<dt>
<a href="kmeans-kmr_8c_source.html">kmeans-kmr.c</a>:
<dd>
is a calculation of K-Means.

<dt>
<a href="kmeans-mrmpi_8cpp_source.html">kmeans-mrmpi.cpp</a> (for reference):
<dd>
is a calculation of K-Means in MapReduce-MPI.

<dt>
<a href="mrmpi-wordfreq_8c_source.html">mrmpi-wordfreq.c</a>:
<dd>
is a word-count.  It is taken from MapReduce-MPI.

<dt>
<a href="phoenix-kmeans_8c_source.html">phoenix-kmeans.c</a>:
<dd>
is a calculation of K-Means.  It works by replicating problem points
data and intermediate k-means results.  It is taken from
Phoenix-MapReduce, but rewritten much.

<dt>
<a href="phoenix-matrix-multiply_8c_source.html">phoenix-matrix-multiply.c</a>:
<dd>
is a simple matrix-multiply.  It works simply by distributing rows.
It is of course slow sequentially, too.  It is taken from
Phoenix-MapReduce, but rewritten much.

<dt>
<a href="graysort_8c_source.html">graysort.c</a>:
<dd>
is a GraySort.  See "http://sortbenchmark.org" for TeraSort
benchmarks.

<dt>
<a href="tpch_8c_source.html">tpch.c</a>:
<dd>
is TPC-H benchmarks.  It runs SQL queries by map-reduce.  See
"http://www.tpc.org/tpch/" for TPC-H benchmarks.

<dt>
<a href="testcxx_8cpp_source.html">testcxx.cpp</a>:
<dd>
is a code in C++11 with a closure.
</dl>

<p>
<img src="kmr.jpg" width=60 height=80/>

<a name="appendixkmrbasics"></a>
<h1>Appendix: KMR Basics</h1>

<p>
A key-value stream (KVS) in KMR is a vector of pairs of a key and a
value, where keys and values are byte arrays with their lengths.  A
key-value stream is actually ordered, especially so after sorting, but
normally the ordering is irrelevant.

<a name="appendixconfigurechanges"></a>
<h1>Appendix: Configure Changes</h1>

<pre class="fragment">
--- ax_mpi.m4.org	Tue Oct  2 15:42:40 2012
+++ ax_mpi.m4	Tue Oct  2 15:44:27 2012
@@ -72,7 +72,7 @@
 AC_LANG_CASE([C], [
 	AC_REQUIRE([AC_PROG_CC])
 	AC_ARG_VAR(MPICC,[MPI C compiler command])
-	AC_CHECK_PROGS(MPICC, mpicc hcc mpxlc_r mpxlc mpcc cmpicc, $CC)
+	AC_CHECK_PROGS(MPICC, mpifccpx mpicc hcc mpxlc_r mpxlc mpcc cmpicc, $CC)
 	ax_mpi_save_CC="$CC"
 	CC="$MPICC"
 	AC_SUBST(MPICC)
@@ -80,7 +80,7 @@
 [C++], [
 	AC_REQUIRE([AC_PROG_CXX])
 	AC_ARG_VAR(MPICXX,[MPI C++ compiler command])
-	AC_CHECK_PROGS(MPICXX, mpic++ mpicxx mpiCC hcp mpxlC_r mpxlC mpCC cmpic++, $CXX)
+	AC_CHECK_PROGS(MPICXX, mpiFCCpx mpic++ mpicxx mpiCC hcp mpxlC_r mpxlC mpCC cmpic++, $CXX)
 	ax_mpi_save_CXX="$CXX"
 	CXX="$MPICXX"
 	AC_SUBST(MPICXX)
@@ -88,7 +88,7 @@
 [Fortran 77], [
 	AC_REQUIRE([AC_PROG_F77])
 	AC_ARG_VAR(MPIF77,[MPI Fortran 77 compiler command])
-	AC_CHECK_PROGS(MPIF77, mpif77 hf77 mpxlf_r mpxlf mpf77 cmpifc, $F77)
+	AC_CHECK_PROGS(MPIF77, mpifrtpx mpif77 hf77 mpxlf_r mpxlf mpf77 cmpifc, $F77)
 	ax_mpi_save_F77="$F77"
 	F77="$MPIF77"
 	AC_SUBST(MPIF77)
@@ -96,7 +96,7 @@
 [Fortran], [
 	AC_REQUIRE([AC_PROG_FC])
 	AC_ARG_VAR(MPIFC,[MPI Fortran compiler command])
-	AC_CHECK_PROGS(MPIFC, mpif90 mpxlf95_r mpxlf90_r mpxlf95 mpxlf90 mpf90 cmpif90c, $FC)
+	AC_CHECK_PROGS(MPIFC, mpifrtpx mpif90 mpxlf95_r mpxlf90_r mpxlf95 mpxlf90 mpf90 cmpif90c, $FC)
 	ax_mpi_save_FC="$FC"
 	FC="$MPIFC"
 	AC_SUBST(MPIFC)
</pre>

<pre class="fragment">
--- ax_openmp.m4.org	Tue Oct  2 15:55:46 2012
+++ ax_openmp.m4	Tue Oct  2 16:05:27 2012
@@ -73,8 +73,9 @@
 AC_CACHE_CHECK([for OpenMP flag of _AC_LANG compiler], ax_cv_[]_AC_LANG_ABBREV[]_openmp, [save[]_AC_LANG_PREFIX[]FLAGS=$[]_AC_LANG_PREFIX[]FLAGS
 ax_cv_[]_AC_LANG_ABBREV[]_openmp=unknown
 # Flags to try:  -fopenmp (gcc), -openmp (icc), -mp (SGI & PGI),
-#                -xopenmp (Sun), -omp (Tru64), -qsmp=omp (AIX), none
-ax_openmp_flags="-fopenmp -openmp -mp -xopenmp -omp -qsmp=omp none"
+#                -xopenmp (Sun), -omp (Tru64), -qsmp=omp (AIX),
+#                -Kopenmp (Fujitsu), none
+ax_openmp_flags="-Kopenmp -fopenmp -openmp -mp -xopenmp -omp -qsmp=omp none"
 if test "x$OPENMP_[]_AC_LANG_PREFIX[]FLAGS" != x; then
   ax_openmp_flags="$OPENMP_[]_AC_LANG_PREFIX[]FLAGS $ax_openmp_flags"
 fi
</pre>
